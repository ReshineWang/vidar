#!/bin/bash
source activate vidar
# your cuda device id
export CUDA_VISIBLE_DEVICES=

# environment variables to be boradcast
export DS_ENV_FILE=""
# hostfile for deepspeed
HOST_FILE=""
# Master node IP of the machine
CHIEF_IP="127.0.0.1"

# Root path for saving experimental results
export SAVE_BASE=""
echo "SAVE_BASE: ${SAVE_BASE}"

# Path suffix for saving experimental results
EXP_NAME="i2v_full_parameter"

# Data jsons dir (output_base_dir/json_path in hyvideo/hyvae_extract/README.md) generated by hyvideo/hyvae_extract/start.sh
# metadata file to be used for training
# could specify one or multiple directories with metadata files
DATA_JSONS_DIR="\
xxx/json_path \
"

current_datetime=$(date +%Y%m%d_%H%M%S)
output_dir="${SAVE_BASE}"
task_flag="${current_datetime}_${EXP_NAME}"

# file store the parameter of the checkpoint 
# could be either a path to a checkpoint or a path to a directory containing checkpoints
CKPT=""

params=" \
    --i2v-dit-weight $CKPT \
    --lr 5e-5 \
    --warmup-num-steps 500 \
    --global-seed 1024 \
    --tensorboard \
    --zero-stage 3 \
    --vae 884-16c-hy \
    --vae-precision fp16 \
    --vae-tiling \
    --denoise-type flow \
    --flow-reverse \
    --flow-shift 7.0 \
    --i2v-mode \
    --model HYVideo-T/2 \
    --video-micro-batch-size 1 \
    --gradient-accumulation-steps 2 \
    --gradient-checkpoint \
    --ckpt-every 500 \
    --embedded-cfg-scale 6.0 \
    "

video_data_params=" \
    --data-type video \
    --data-jsons-path ${DATA_JSONS_DIR} \
    --sample-n-frames 60 \
    --sample-stride 4 \
    --num-workers 8 \
    --uncond-p 0.1 \
    --sematic-cond-drop-p 0.1 \
    "

te_params=" \
    --text-encoder llm-i2v \
    --text-encoder-precision fp16 \
    --text-states-dim 4096 \
    --text-len 256 \
    --tokenizer llm-i2v \
    --prompt-template dit-llm-encode-i2v \
    --prompt-template-video dit-llm-encode-video-i2v \
    --hidden-state-skip-layer 2 \
    --text-encoder-2 clipL \
    --text-encoder-precision-2 fp16 \
    --text-states-dim-2 768 \
    --tokenizer-2 clipL \
    --text-len-2 77 \
    "

# use lora
# lora_params=" \
#     --use-lora \
#     --lora-rank 64 \
#     "

# use full parameter
lora_params=""

export TOKENIZERS_PARALLELISM=false

set -x


# single node, multi gpu
#deepspeed --include localhost:0,1,2,3,4,5,6,7 --master_addr "${CHIEF_IP}" \

# multiple node, multiple gpu
deepspeed --hostfile=$HOST_FILE --master_addr "${CHIEF_IP}" \
    train_vm.py \
    ${params} \
    ${val_params} \
    ${video_data_params} \
    ${te_params} \
    ${lora_params} \
    --task-flag ${task_flag} \
    --output-dir ${output_dir} \
    "$@"
